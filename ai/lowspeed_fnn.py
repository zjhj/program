# -*- coding: utf-8 -*-
"""keras_FNN_低速率小区.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dc_uNkRB-QS2Wo5-KCnGnI0BdHH9G-Ew

# 移动低速率小区预测(基于tensorflow2.x)
案例描述

造成LTE网络小区下载速率较低的原因主要是在无线侧，其次还有一些是传输问题或者是核心网问题所致，此外，还可以通过参数调整优化及一些特殊新功能的开启来进行下载速率的提升。但是，如果能提前预知低速率的小区，对于网优人员，可以更好的主动的解决网络问题，提升用户满意度。

字段描述
1.   cgi		小区标识
2.   LOWSPEED		是否低速率小区
3.   SUC_CALL_RATE		无线接通率
4.   PRB_UTILIZE_RATE		无线利用率
5.   mr		MR覆盖率
6.   cover_type		覆盖类型
7.   erabnbrmaxestab1		QCI1最大E-RAB数
8.   upspeed		网络上行速率

# 1.导入相关依赖库
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
print(tf.__version__)
print(keras.__version__)

"""# 2.准备数据"""
df = pd.read_csv('lowspeed.csv',sep=',',encoding='utf-8')
df.head()

"""# 数据探索与预处理"""

# 数据没有缺失，'cgi'字段有英文字符
df.info()

# 去掉字符串类型的列
df.drop('cgi',axis=1,inplace=True)
df.head(2)

# 样本数据明显不均衡，正样本52905，负样本2774，需要做样本均衡处理。
df['LOWSPEED'].value_counts().to_dict()

'''随机选择2774条正样本数据与2774条负样本数据，合并为一个新的二维数组。'''
#索引--异常
fraud_indices = np.array(df[df['LOWSPEED']==1].index)

#索引--正常
normal_indices = np.array(df[df['LOWSPEED']==0].index)

#索引--正常--随机取len(fraud_indices)
randome_normal_indices = np.random.choice(normal_indices,len(fraud_indices),replace=False)

#索引合并
indices = np.concatenate([fraud_indices,randome_normal_indices])

#更具索引取数据
df = df.loc[indices]

df['LOWSPEED'].value_counts().to_dict()

# 数据拆分为x,y即feature与label
cols = df.columns.values.tolist()
df1 = df.copy()
x = df1.loc[:,[col for col in cols if col!='LOWSPEED']]
print(x.shape)
y = df.loc[:,['LOWSPEED']]
print(y.shape)

# 数据拆分为训练与测试，比例为0.7：0.3
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)

# 数据标准化
sc = StandardScaler()
sc.fit(x_train)
sc.fit(x_test)
x_train_std = sc.transform(x_train)
x_test_std = sc.transform(x_test)

"""# 3.建立模型"""

model = keras.Sequential()
model.add(keras.layers.Dense(12, input_dim=7, activation='relu'))
model.add(keras.layers.Dense(7, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.summary()

"""# 4.训练模型"""

# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Recall()])
# fit the keras model on the dataset
model.fit(x_train_std, y_train, epochs=10, batch_size=10)

"""# 5.评估模型"""

score = model.evaluate(x_test_std, y_test, verbose=0)
print("Val loss:", score[0])
print("Val accuracy:", score[1])

from sklearn.metrics import f1_score, confusion_matrix
y_pred = pd.DataFrame(model.predict(x_test_std))
#预测值y>0.5设置为1
#预测值y<=0.5设置为0
y_pred[y_pred > 0.5]=1
y_pred[y_pred <= 0.5]=0
# print(y_test['LOWSPEED'])
# print(y_pred)

# Print f1, precision, and recall scores
print(confusion_matrix(y_test, y_pred))
print(f1_score(y_test, y_pred , average="macro"))

"""# 6.保存模型"""

json_string = model.to_json()#等价于 json_string = model.get_config()  
open('my_model_architecture.json','w').write(json_string)    
model.save('my_lowspeed_model.h5')

